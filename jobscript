#!/bin/bash --login
#$ -cwd
#$ -l nvidia_v100            # Can instead use 'nvidia_a100' for the A100 GPUs (if permitted!)
run_command() {
    local data=$1

    # Use command based on dataset
    if [[ $data == "wikipedia_fm" ]]; then
        python main.py -d wikipedia_fm --pos_dim 108 --bs 32 --n_degree 64 --n_layer 1 --mode t --bias 1e-5 --pos_enc lp --walk_pool sum --seed 123
        python main.py -d wikipedia_fm --pos_dim 108 --bs 32 --n_degree 64 1 --mode i --bias 1e-5 --pos_enc lp --walk_pool sum --seed 0
    elif [[ $data == "reddit_fm" ]]; then
        python main.py -d reddit_fm --pos_dim 108 --bs 32 --n_degree 64 --n_layer 1 --mode t --bias 1e-5 --pos_enc lp --walk_pool sum --seed 123
        python main.py -d reddit_fm --pos_dim 108 --bs 32 --n_degree 64 1 --mode i --bias 1e-5 --pos_enc lp --walk_pool sum --seed 0
    if [[ $data == "social" ]]; then
        python main.py -d socialevolve --pos_dim 108 --bs 32 --n_degree 64 --n_layer 1 --mode t --bias 1e-5 --pos_enc lp --walk_pool sum --seed 123
        python main.py -d socialevolve --pos_dim 108 --bs 32 --n_degree 64 1 --mode i --bias 1e-5 --pos_enc lp --walk_pool sum --seed 0
    fi
}

conda activate ja
module load libs/cuda/11.7.0

# Copy a directory of files from scratch to the GPU node's local NVMe storage
cp -r ~/scratch/CAW/ $TMPDIR

# Process the data with a GPU app, from within the local NVMe storage area
cd $TMPDIR/CAW/
run_command $1

# Copy the results back to the main scratch area
rsync -av $TMPDIR/CAW/log/ ~/scratch/CAW/log/
rsync -av $TMPDIR/CAW/results/ ~/scratch/CAW/results/
rsync -av $TMPDIR/CAW/saved_checkpoints/ ~/scratch/CAW/saved_checkpoints/
rsync -av $TMPDIR/CAW/saved_models/ ~/scratch/CAW/saved_models/

# The batch system will automatically delete the contents of $TMPDIR at the end of your job.
cd ~/scratch/CAW/
git pull
git add ./log/
git commit -m "logs updated"
git push

sleep 3
#$ -m ea
#$ -M jiafeng.xiong@manchester.ac.uk     # Send email when finished.